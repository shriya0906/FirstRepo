{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GAN-pytorch.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMch2YNSekqLBCnUufsrM/k",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shriya0906/FirstRepo/blob/master/GAN_pytorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install cloud-tpu-client==0.10 https://storage.googleapis.com/tpu-pytorch/wheels/torch_xla-1.9-cp37-cp37m-linux_x86_64.whl"
      ],
      "metadata": {
        "id": "CgEOj_qSiLpa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pytorch-lightning"
      ],
      "metadata": {
        "id": "ACUWEEgLidfi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch torchvision torchaudio \n"
      ],
      "metadata": {
        "id": "dvIUlZ9Jih2a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall cloud-tpu-client"
      ],
      "metadata": {
        "id": "gejUjtzkjt9j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install"
      ],
      "metadata": {
        "id": "P8bMrsaekC1C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get install"
      ],
      "metadata": {
        "id": "J-0hqS8AkHcx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade pytorch-lightning"
      ],
      "metadata": {
        "id": "1Jj1Vf7zl4Ky"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "import torch\n",
        "import torchvision\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import torchvision.datasets as datasets\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "from torchvision.datasets import mnist\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import pytorch_lightning as pl\n",
        "\n",
        "random_seed = 42\n",
        "torch.manual_seed(random_seed)\n",
        "\n",
        "BATCH_SIZE=128\n",
        "AVAIL_GPUS = min(1, torch.cuda.device_count())\n",
        "NUM_WORKERS=int(os.cpu_count() / 2)"
      ],
      "metadata": {
        "id": "adpr6QKeC3UV"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "3-7eWLV8iJe0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MNISTDataModule(pl.LightningDataModule):\n",
        "  def __init__(self, data_dir=\"./data\", \n",
        "              batch_size=BATCH_SIZE, num_workers=NUM_WORKERS):\n",
        "    super().__init__()\n",
        "    self.data_dir = batch_size\n",
        "    self.num_workers = num_workers\n",
        "\n",
        "    self.transform = transforms.Compose(\n",
        "        [\n",
        "            transforms.ToTensor(),\n",
        "         transforms.Normalize((0.1307,), (0.3081,)),\n",
        "        ]\n",
        "    )\n",
        "\n",
        "def prepare_data(self):\n",
        "  MNIST(self.data_dir, train=True, download=True)\n",
        "  MNIST(self.data_dir, train=False, download=True)\n",
        "\n",
        "  def setup(self, stage=None):\n",
        "\n",
        "  # Assign train/val datasets\n",
        "    if stage == \"fit\" or stage is None:\n",
        "      mnist_full = MNIST(self.data_dir, train=True, transform=self.transofrm)\n",
        "    self.mnist_train, self.mnist_val = random_split(mnist_full, [55000, 5000])\n",
        "\n",
        "    # Assign test dataset\n",
        "    if stage == \"test\" or stage is None:\n",
        "      self.mnist_test = MNIST(self.data_dir, train=False, transform=self.transform)\n",
        "\n",
        "      def train_dataloader(self):\n",
        "        return DataLoader(self.mnist_train, batch_size=self.batch_size, num_workers=self.num_workers)\n",
        "\n",
        "      def val_dataloader(self):\n",
        "        return DataLoader(self.mnist_val, batch_size=self.batch_size, num_workers=self.num_workers)\n",
        "\n",
        "        def test_dataloader(self):\n",
        "          return DataLoader(self.mnist_test, batch_size=self.batch_size, num_workers=self.num_workers)\n",
        "\n"
      ],
      "metadata": {
        "id": "P-0HC9wuHMib"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Detective: fake or no fake -> 1 output [0,1]\n",
        "class Discriminator(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    #Simple CNN\n",
        "    self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n",
        "    self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
        "    self.conv2_drop = nn.Dropout2d()\n",
        "    self.fc1 = nn.Linear(320, 50)\n",
        "    self.fc2 = nn.Linear(50, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "      x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
        "      x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
        "      #Flatten the tensor so it can be fed into the FC layers\n",
        "      x = x.view(-1, 320)\n",
        "      x = F.relu(self.fc1(x))\n",
        "      x = F.dropout(x, training=self.training)\n",
        "      x = self.fc2(x)\n",
        "      return torch.sigmoid(x)"
      ],
      "metadata": {
        "id": "cZHS3CxEKt0T"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.nn.modules.conv import Conv2d\n",
        "# Generate Fake Data: output like real data [1, 28, 28] and values -1, 1\n",
        "class Generator(nn.Module):\n",
        "  def __init__(self, latent_dim):\n",
        "    super().__init__()\n",
        "    self.lin1 = nn.Linear(latent_dim, 7*7*64) #[n, 256, 7, 7]\n",
        "    self.ct1 = nn.ConvTranspose2d(64, 32, 4, stride=2) # [n, 64, 16, 16]\n",
        "    self.ct2 = nn.ConvTranspose2d(32, 16, 4, stride=2) # [n, 16, 34, 34]\n",
        "    self.conv = nn. Conv2d(16, 1, kernel_size=7) #[n, 1, 28, 28]\n",
        "\n",
        "    def forward(self, x):\n",
        "      #Pass latent space input into linear layer and reshape\n",
        "      x = self.lin1(x)\n",
        "      x = F.relu(x)\n",
        "      x = x.view(-1, 64, 7, 7) #256\n",
        "\n",
        "      # Upsample (transposed conv) 16x16 (64 feature maps)\n",
        "      x = self.ct1(x)\n",
        "      x = F.relu(x)\n",
        "\n",
        "      #Upsample to 34*34 (16 feature maps)\n",
        "      x = self.ct2(x)\n",
        "      x = F.relu(x)\n",
        "      \n",
        "      #Convolution to 28*28 (1 feature map)\n",
        "      return self.conv(x)\n",
        "    "
      ],
      "metadata": {
        "id": "flf8q9XDMkth"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#TODO: GAN\n",
        "class GAN(pl.LightningModule):\n",
        "  def __init__(self, latent_dim=100, lr=0.0002):\n",
        "    super().__init__()\n",
        "    self.save_hyperparameters()\n",
        "\n",
        "    self.generator = Generator(latent_dim=self.hparams.latent_dim)\n",
        "    self.discriminator = Discriminator()\n",
        "\n",
        "    #random noise\n",
        "    self.validation_z = torch.randn(6, self.hparams.latent_dim)\n",
        "\n",
        "    def forward(self, z):\n",
        "      return self.generator(z)\n",
        "\n",
        "    def adversarial_loss(self, y_hat, y):\n",
        "        return F.binary_cross_entropy(y_hat, y)\n",
        "\n",
        "    def training_step(self, batch, batch_idx, optimizer_idx):\n",
        "          real_imgs, _ = batch\n",
        "\n",
        "          #sample noise\n",
        "          z = torch.randn(real_imgs.shape[0], self.hparams.latent_dim)\n",
        "          z = z.type_as(real_imgs)\n",
        "\n",
        "          #train generator: max log(D(G(z)))\n",
        "          if optimizer_idx == 0:\n",
        "            fake_imgs = self(z)\n",
        "            y_hat = self.discriminator(fake_imgs)\n",
        "\n",
        "            y = torch.ones(real_imgs.size(0), 1)\n",
        "            y = y.type_as(real_imgs)\n",
        "\n",
        "            g_loss = self.adversarial_loss(y_hat, y)\n",
        "\n",
        "            log_dict = {\"g_loss\": g_loss}\n",
        "            return {\"loss\": g_loss, \"progress_bar\": log_dict, \"log\": log_dict}\n",
        "\n",
        "         #train discriminator: max log (D(x)) + log(1 - D(G(z)))\n",
        "            if optimizer_idx == 1:\n",
        "\n",
        "              # how well can it label as real\n",
        "              y_hat_real = self.discriminator(real_imgs)\n",
        "\n",
        "              y_real = torch.ones(real_imgs.size(0), 1)\n",
        "              y_real = y_real.type_as(real_imgs)\n",
        "\n",
        "              real_loss = self.adversarial_loss(y_hat_real, y_real)\n",
        "\n",
        "              # how well can it label as fake\n",
        "              y_hat_fake = self.discriminator(self(z).detach())\n",
        "\n",
        "              y_fake = torch.zeros(real_imgs.size(0), 1)\n",
        "              y_fake = y_fake.type_as(real_imgs)\n",
        "\n",
        "              fake_loss = self.adversarial_loss(y_hat_fake, y_fake)\n",
        "\n",
        "              d_loss = (real_loss + fake_loss) / 2\n",
        "              log_dict = {\"d_loss\": d_loss}\n",
        "              return{\"loss\": d_loss, \"progress_bar\": log_dict, \"log\": log_dict}\n",
        "\n",
        "          def configure_optimizers(self):\n",
        "            lr = self.hparams.lr\n",
        "            opt_g = torch.optim.Adam(self.generator.parameters(), lr=lr)\n",
        "            opt_d = torch.optim.Adam(self.discriminator.parameters(), lr=lr)\n",
        "            return[opt_g, opt_d], []\n",
        "\n",
        "    def plot_imgs(Self):\n",
        "              z = self.validations_z.type_as(self.generator.lin1.weight)\n",
        "              sample_imgs = self(z).cpu()\n",
        "\n",
        "              print('epoch', self.current_epoch)\n",
        "              fig = plt.figure()\n",
        "              for i in range(sample_imgs.size(0)):\n",
        "                plt.subplot(2, 3, i+1)\n",
        "                plt.tight_layout()\n",
        "                plt.imshow(sample_imgs.detach() [i, 0, :, :], cmap='gray_r', interpolation='none')\n",
        "                plt.title(\"Generated Data\")\n",
        "                plt.xticks([])\n",
        "                plt.yticks([])\n",
        "                plt.axis('off')\n",
        "                plt.show()\n",
        "\n",
        "    def on_epoch_end(self):\n",
        "              self.plot_imgs()\n"
      ],
      "metadata": {
        "id": "XIaX5g22O9Hu"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install python-mnist"
      ],
      "metadata": {
        "id": "JLKADmbEr4yQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dm = MNISTDataModule()\n",
        "model = GAN()"
      ],
      "metadata": {
        "id": "c85J9yD_gKEz"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.plot_imgs()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        },
        "id": "sCtrGgAcgVr0",
        "outputId": "d50c708a-36a2-4ece-c30a-c7f2999af19a"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-50-dec6df893dc2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot_imgs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1206\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1207\u001b[0m         raise AttributeError(\"'{}' object has no attribute '{}'\".format(\n\u001b[0;32m-> 1208\u001b[0;31m             type(self).__name__, name))\n\u001b[0m\u001b[1;32m   1209\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1210\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Module'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'GAN' object has no attribute 'plot_imgs'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = pl.Trainer(max_epochs=20, gpus=AVAIL_GPUS)\n",
        "trainer.fit(model, dm)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 415
        },
        "id": "HpY1kturp4c0",
        "outputId": "9022be0c-db81-4a98-c61d-855b3518a7fb"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "GPU available: False, used: False\n",
            "TPU available: False, using: 0 TPU cores\n",
            "IPU available: False, using: 0 IPUs\n",
            "HPU available: False, using: 0 HPUs\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "MisconfigurationException",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mMisconfigurationException\u001b[0m                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-51-77dee2b5ad57>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtrainer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgpus\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mAVAIL_GPUS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    769\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    770\u001b[0m         self._call_and_handle_interrupt(\n\u001b[0;32m--> 771\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit_impl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dataloaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_dataloaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdatamodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mckpt_path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    772\u001b[0m         )\n\u001b[1;32m    773\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36m_call_and_handle_interrupt\u001b[0;34m(self, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    721\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlauncher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlaunch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainer_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    722\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 723\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mtrainer_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    724\u001b[0m         \u001b[0;31m# TODO: treat KeyboardInterrupt as BaseException (delete the code below) in v1.7\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    725\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexception\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36m_fit_impl\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    809\u001b[0m             \u001b[0mckpt_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_provided\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_connected\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlightning_module\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    810\u001b[0m         )\n\u001b[0;32m--> 811\u001b[0;31m         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mckpt_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mckpt_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    812\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    813\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstopped\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, model, ckpt_path)\u001b[0m\n\u001b[1;32m   1158\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callback_connector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_attach_model_logging_functions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1159\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1160\u001b[0;31m         \u001b[0mverify_loop_configurations\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1162\u001b[0m         \u001b[0;31m# hook\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/configuration_validator.py\u001b[0m in \u001b[0;36mverify_loop_configurations\u001b[0;34m(trainer)\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Unexpected: Trainer state fn must be set before validating loop configuration.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTrainerFn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFITTING\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTrainerFn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTUNING\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m         \u001b[0m__verify_train_val_loop_configuration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m         \u001b[0m__verify_manual_optimization_support\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0m__check_training_step_requires_dataloader_iter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/configuration_validator.py\u001b[0m in \u001b[0;36m__verify_train_val_loop_configuration\u001b[0;34m(trainer, model)\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhas_training_step\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m         raise MisconfigurationException(\n\u001b[0;32m---> 76\u001b[0;31m             \u001b[0;34m\"No `training_step()` method defined. Lightning `Trainer` expects as minimum a\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m             \u001b[0;34m\" `training_step()`, `train_dataloader()` and `configure_optimizers()` to be defined.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m         )\n",
            "\u001b[0;31mMisconfigurationException\u001b[0m: No `training_step()` method defined. Lightning `Trainer` expects as minimum a `training_step()`, `train_dataloader()` and `configure_optimizers()` to be defined."
          ]
        }
      ]
    }
  ]
}